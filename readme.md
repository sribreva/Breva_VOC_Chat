# Breva Voiceâ€‘ofâ€‘Customer (VOC) Pipeline

A **4â€‘script toolchain** that turns raw survey CSVs into a fully searchable, summarized knowledge base and exposes it through a Streamlit chatbot.

---

## 1Â Â Architecture at a Glance

### 1.1Â Recommended "Oneâ€‘Shot" Flow (raw *and* summaries sent to Pinecone)

```text
CSV â”€â–¶ â‘  VOC_chroma_db_upload.py  â”€â”
                                   â”‚ vectors + metadata
                                   â–¼
                              ChromaDB (voc_responses)
                                   â”‚
                                   â–¼
                            â‘¡ VOC_map_reduce.py
                              (adds *_summary docs)
                                   â”‚
                                   â–¼
                            â‘¢ VOC_chroma_to_pinecone.py
                              (migrate ALL docs)
                                   â”‚
                                   â–¼
                            Pinecone index (voc-indexâ€‘*)
                                   â”‚
                                   â–¼
                          â‘£ app.py  (Streamlit chatbot)
```

**Why this order?** A *single* migration (StepÂ â‘¢) pushes both raw responses **and** metaâ€‘summaries to Pinecone, keeping the search index in sync.

### 1.2Â Legacy Flow (two migrations)

```text
CSV â†’ â‘  Upload â†’ ChromaDB
           â”‚
           â–¼
â‘¢ Migrate raw vectors â†’ Pinecone  (first pass)
           â”‚
           â–¼
â‘¡ Mapâ€‘reduce summaries â†’ ChromaDB
           â”‚
           â–¼
â‘¢ Migrate again â†’ Pinecone        (push summaries)
```

If you already ran the first migration, **rerun StepÂ â‘¢** after StepÂ â‘¡ finishes so the `*_summary` docs make it to Pinecone.

---

## 2Â Â Script Cheatâ€‘Sheet

| # | Script                      | What It Does                                                                                                     | Key Inputs                                                    | Key Outputs                                        |
| - | --------------------------- | ---------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------- | -------------------------------------------------- |
| â‘  | `VOC_chroma_db_upload.py`   | Reads the CSV, cleans & chunks text, embeds with **Sentenceâ€‘Transformer**, stores in **ChromaDB**                | `--csv`, `--persist_dir`, `--do-clustering`, `--chunk_tokens` | `voc_responses` collection with vectors & metadata |
| â‘¡ | `VOC_map_reduce.py`         | Batches responses per `question_type`, calls **Claude Haiku â€¢ Sonnet**, stores `*_summary` docs back to ChromaDB | `--batch-size`, `ANTHROPIC_API_KEY`                           | New docs tagged `question_type: <type>_summary`    |
| â‘¢ | `VOC_chroma_to_pinecone.py` | Pulls *everything* from ChromaDB and upserts to **Pinecone** (V2 API)                                            | `--chroma-dir`, `--index-name`, `PINECONE_API_KEY`            | Pinecone vectors with full metadata (incl. `text`) |
| â‘£ | `app.py`                    | Streamlit UI â†’ maps user query â†’ finds matching summary in Pinecone â†’ crafts Claude prompt â†’ chat                | `pinecone_api_key`, `anthropic_api_key`, `index_name`         | Web app at `http://localhost:8501`                 |

---

## 3Â Â Prerequisites

```bash
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt  # chromadb, pinecone-client, anthropic, streamlit, etc.
```

Set secrets (bash or `.env`):

```bash
export PINECONE_API_KEY="â€¦"
export ANTHROPIC_API_KEY="â€¦"
# (optional) AZURE_OPENAI_API_KEY, AZURE_OPENAI_ENDPOINT
```

A GPU is nice but optional.

---

## 4Â Â Stepâ€‘byâ€‘Step (Recommended Flow)

1. **Embed & store raw data**

   ```bash
   python VOC_chroma_db_upload.py \
     --csv data/merged_grant_applications_q2_2025.csv \
     --persist_dir chroma_db_q2_2025 \
     --no-clustering
   ```

2. **Generate mapâ€‘reduce summaries**

   ```bash
   python VOC_map_reduce.py --batch-size 100 \
     --persist_dir chroma_db_q2_2025
   ```

   The script loops until every `question_type` has a metaâ€‘summary.

3. **Migrate ALL docs to Pinecone**

   ```bash
   python VOC_chroma_to_pinecone.py \
     --chroma-dir chroma_db_q2_2025 \
     --index-name voc-index-2025-q2 \
     --batch-size 100
   ```

4. **Launch the chatbot**

   ```bash
   streamlit run app.py
   ```

   Ask something like *"What challenges do founders have with cashâ€‘flow forecasting?"* â€” the app fetches the cached summary and responds via Claude.

---

## 5Â Â Where to Tweak Hardâ€‘coded Paths / Keys

| Location            | Variable             | Default                                   | Suggestion                       |
| ------------------- | -------------------- | ----------------------------------------- | -------------------------------- |
| **upload.py**       | `persist_directory`  | `/Users/â€¦/chroma_database_update_2025_q2` | Pass via `--persist_dir`         |
|                     | CSV path in `main()` | absolute path                             | Promote to `argparse` flag       |
| **map\_reduce.py**  | `anthropic_api_key`  | hardâ€‘coded                                | Use `os.environ` + `argparse`    |
| **to\_pinecone.py** | `--pinecone-api-key` | hardâ€‘coded sample                         | Remove default, require flag/env |
| **app.py**          | fallback secrets     | hardâ€‘coded sample                         | Store in **StreamlitÂ Secrets**   |

---

## 6Â Â Tips & Tricks

- **Chunking** (`--chunk_tokens`) helps with very long answers; leaveÂ 0 to store full response.
- To **dedupe** bad responses, adjust `VOCDatabaseCreator.preprocess_text()`.
- **Pinecone â€œstarterâ€ pod** keeps costs low (<5M vectors free).
- **Streamlit hotâ€‘reload**: `streamlit run app.py --server.runOnSave true`.
- Rotate keys before pushing to Git.

---

## 7Â Â Roadmap

-

Contributions welcomeÂ ğŸ‰

